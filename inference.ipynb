{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "super-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import measure\n",
    "import numpy as np\n",
    "import timeit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "from openvino.runtime import Core, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lined-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"pifu_ov\"\n",
    "RESOLUTION = 256\n",
    "TEST_FOLDER_PATH = \"./input_images\"\n",
    "RESULTS_PATH = \"./results\"\n",
    "Z_SIZE = 200.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sonic-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global LOADSIZE\n",
    "def load_image(image_path, mask_path):\n",
    "        self_transforms = transforms.Compose([\n",
    "            transforms.Resize(512),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        # Name\n",
    "        img_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        # Calib\n",
    "        B_MIN = np.array([-1, -1, -1])\n",
    "        B_MAX = np.array([1, 1, 1])\n",
    "        projection_matrix = np.identity(4)\n",
    "        projection_matrix[1, 1] = -1\n",
    "        calib = torch.Tensor(projection_matrix).float()\n",
    "        # Mask\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        mask = transforms.Resize(512)(mask)\n",
    "        mask = transforms.ToTensor()(mask).float()\n",
    "        # image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self_transforms(image)\n",
    "        image = mask.expand_as(image) * image\n",
    "        # Return JSON \n",
    "        return {\n",
    "            'name': img_name,\n",
    "            'img': image.unsqueeze(0),\n",
    "            'calib': calib.unsqueeze(0),\n",
    "            'mask': mask.unsqueeze(0),\n",
    "            'b_min': B_MIN,\n",
    "            'b_max': B_MAX,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unique-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj_mesh_with_color(mesh_path, verts, faces, colors):\n",
    "    file = open(mesh_path, 'w')\n",
    "\n",
    "    for idx, v in enumerate(verts):\n",
    "        c = colors[idx]\n",
    "        file.write('v %.4f %.4f %.4f %.4f %.4f %.4f\\n' % (v[0], v[1], v[2], c[0], c[1], c[2]))\n",
    "    for f in faces:\n",
    "        f_plus = f + 1\n",
    "        file.write('f %d %d %d\\n' % (f_plus[0], f_plus[2], f_plus[1]))\n",
    "    file.close()\n",
    "\n",
    "# pure np\n",
    "def batch_eval(points, eval_func, num_samples=512 * 512 * 512):\n",
    "    num_pts = points.shape[1]\n",
    "    sdf = np.zeros(num_pts)\n",
    "\n",
    "    num_batches = num_pts // num_samples\n",
    "    for i in range(num_batches):\n",
    "        sdf[i * num_samples:i * num_samples + num_samples] = eval_func(\n",
    "            points[:, i * num_samples:i * num_samples + num_samples])\n",
    "    if num_pts % num_samples:\n",
    "        sdf[num_batches * num_samples:] = eval_func(points[:, num_batches * num_samples:])\n",
    "\n",
    "    return sdf\n",
    "\n",
    "# pure np\n",
    "def eval_grid_octree(coords, eval_func,init_resolution=64, threshold=0.01,num_samples=512 * 512 * 512):\n",
    "    resolution = coords.shape[1:4]\n",
    "\n",
    "    sdf = np.zeros(resolution)\n",
    "\n",
    "    dirty = np.ones(resolution, dtype=np.bool)\n",
    "    grid_mask = np.zeros(resolution, dtype=np.bool)\n",
    "\n",
    "    reso = resolution[0] // init_resolution\n",
    "\n",
    "    while reso > 0:\n",
    "        grid_mask[0:resolution[0]:reso, 0:resolution[1]:reso, 0:resolution[2]:reso] = True\n",
    "        test_mask = np.logical_and(grid_mask, dirty)\n",
    "        points = coords[:, test_mask]\n",
    "        \n",
    "        sdf[test_mask] = batch_eval(points, eval_func, num_samples=num_samples)\n",
    "        \n",
    "        dirty[test_mask] = False\n",
    "        \n",
    "        # do interpolation\n",
    "        if reso <= 1:\n",
    "            break\n",
    "        for x in range(0, resolution[0] - reso, reso):\n",
    "            for y in range(0, resolution[1] - reso, reso):\n",
    "                for z in range(0, resolution[2] - reso, reso):\n",
    "                    if not dirty[x + reso // 2, y + reso // 2, z + reso // 2]:\n",
    "                        continue\n",
    "                    v0 = sdf[x, y, z]\n",
    "                    v1 = sdf[x, y, z + reso]\n",
    "                    v2 = sdf[x, y + reso, z]\n",
    "                    v3 = sdf[x, y + reso, z + reso]\n",
    "                    v4 = sdf[x + reso, y, z]\n",
    "                    v5 = sdf[x + reso, y, z + reso]\n",
    "                    v6 = sdf[x + reso, y + reso, z]\n",
    "                    v7 = sdf[x + reso, y + reso, z + reso]\n",
    "                    v = np.array([v0, v1, v2, v3, v4, v5, v6, v7])\n",
    "                    v_min = v.min()\n",
    "                    v_max = v.max()\n",
    "                    # this cell is all the same\n",
    "                    if (v_max - v_min) < threshold:\n",
    "                        sdf[x:x + reso, y:y + reso, z:z + reso] = (v_max + v_min) / 2\n",
    "                        dirty[x:x + reso, y:y + reso, z:z + reso] = False\n",
    "        reso //= 2\n",
    "\n",
    "    return sdf.reshape(resolution)\n",
    "\n",
    "# pure np\n",
    "def create_grid(resX, resY, resZ, b_min=np.array([0, 0, 0]), b_max=np.array([1, 1, 1])):\n",
    "    coords = np.mgrid[:resX, :resY, :resZ]\n",
    "    coords = coords.reshape(3, -1)\n",
    "    coords_matrix = np.eye(4)\n",
    "    length = b_max - b_min\n",
    "    coords_matrix[0, 0] = length[0] / resX\n",
    "    coords_matrix[1, 1] = length[1] / resY\n",
    "    coords_matrix[2, 2] = length[2] / resZ\n",
    "    coords_matrix[0:3, 3] = b_min\n",
    "    coords = np.matmul(coords_matrix[:3, :3], coords) + coords_matrix[:3, 3:4]\n",
    "    coords = coords.reshape(3, resX, resY, resZ)\n",
    "    return coords, coords_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "binary-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction(net, cuda, calib_tensor,\n",
    "                   resolution, b_min, b_max,\n",
    "                   use_octree=False, num_samples=10000):\n",
    "    \n",
    "    coords, mat = create_grid(resolution, resolution, resolution,b_min, b_max)\n",
    "    def eval_func(points):\n",
    "        points = np.expand_dims(points, axis=0)\n",
    "        points = np.repeat(points, net.num_views, axis=0)\n",
    "        samples = torch.from_numpy(points).to(device=cuda).float()\n",
    "        net.query(samples, calib_tensor)\n",
    "        \n",
    "        pred = net.get_preds()[0][0]\n",
    "        return pred.detach().cpu().numpy()\n",
    "        #return pred\n",
    "\n",
    "    # Then we evaluate the grid\n",
    "    \n",
    "    sdf = eval_grid_octree(coords, eval_func, num_samples=num_samples)\n",
    "\n",
    "    # Finally we do marching cubes\n",
    "    try:\n",
    "        verts, faces, normals, values = measure.marching_cubes_lewiner(sdf, 0.5)\n",
    "        # transform verts into world coordinate system\n",
    "        verts = np.matmul(mat[:3, :3], verts.T) + mat[:3, 3:4]\n",
    "        verts = verts.T\n",
    "        return verts, faces, normals, values\n",
    "    except:\n",
    "        print('error cannot marching cubes')\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-fiber",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "imported-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(feat, uv):\n",
    "    uv = uv.transpose(1, 2)  # [B, N, 2]\n",
    "    uv = uv.unsqueeze(2)  # [B, N, 1, 2]\n",
    "    samples = torch.nn.functional.grid_sample(feat, uv, align_corners=True)  # [B, C, N, 1]\n",
    "    return samples[:, :, :, 0]  # [B, C, N]\n",
    "\n",
    "def orthogonal(points, calibrations):\n",
    "    rot = calibrations[:, :3, :3]\n",
    "    trans = calibrations[:, :3, 3:4]\n",
    "    pts = torch.baddbmm(trans, rot, points)  # [B, 3, N]\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "female-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGPIFuNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HGPIFuNet, self).__init__()\n",
    "        self.name = 'hgpifu'\n",
    "        \n",
    "        self.index = index\n",
    "        self.projection = orthogonal\n",
    "\n",
    "        self.preds = None\n",
    "        self.num_views = 1\n",
    "\n",
    "        ##############\n",
    "        #  OV field  #\n",
    "        ##############\n",
    "        self.core = Core()\n",
    "        self.device_name = 'CPU'\n",
    "        self.HGF_path = './OV_model/FP16//HGFilter.xml'\n",
    "        self.SC_path = './OV_model/FP16/SurfaceClassifier.xml'\n",
    "        self.OV_int()\n",
    "        \n",
    "        self.im_feat_list = []\n",
    "        self.tmpx = None\n",
    "        self.normx = None\n",
    "\n",
    "        self.intermediate_preds_list = []\n",
    "        \n",
    "        self.time_benchmark = 0\n",
    "\n",
    "    def OV_int(self):\n",
    "        HGF = self.core.read_model(self.HGF_path)\n",
    "        self.HGF = self.core.compile_model(HGF, self.device_name)\n",
    "        \n",
    "        SC = self.core.read_model(self.SC_path)\n",
    "        SC.reshape(\"1, 257, ?\")\n",
    "        self.SC = self.core.compile_model(SC, self.device_name)\n",
    "        \n",
    "        \n",
    "\n",
    "    # replacing normalizer class member to class function.\n",
    "    def normalizer(self, z):\n",
    "        z_feat = z * (512 // 2) / Z_SIZE\n",
    "        return z_feat\n",
    "\n",
    "    \n",
    "    def filter(self, images):\n",
    "        \n",
    "        st = timeit.default_timer()\n",
    "        input_tensor = images.cpu().numpy()\n",
    "        self.time_benchmark += timeit.default_timer() - st\n",
    "        \n",
    "        results = self.HGF.infer_new_request({0: input_tensor})\n",
    "        \n",
    "        st = timeit.default_timer()\n",
    "        for i, (k, v) in enumerate(results.items()):\n",
    "            if i == 3:\n",
    "                temp = torch.tensor(v).to('cpu')\n",
    "            if i == 4:\n",
    "                self.tmpx = torch.tensor(v).to('cpu')\n",
    "            if i == 5:\n",
    "                self.normx = torch.tensor(v).to('cpu')\n",
    "        \n",
    "        self.time_benchmark += timeit.default_timer() - st\n",
    "\n",
    "        self.im_feat_list = [temp]\n",
    "            \n",
    "            \n",
    "    def query(self, points, calibs):\n",
    "        xyz = self.projection(points, calibs)\n",
    "        xy = xyz[:, :2, :]\n",
    "        z = xyz[:, 2:3, :]\n",
    "\n",
    "        in_img = (xy[:, 0] >= -1.0) & (xy[:, 0] <= 1.0) & (xy[:, 1] >= -1.0) & (xy[:, 1] <= 1.0)\n",
    "        \n",
    "        z_feat = self.normalizer(z)\n",
    "\n",
    "        self.intermediate_preds_list = []\n",
    "        infer_request = self.SC.create_infer_request()\n",
    "       \n",
    "        for im_feat in self.im_feat_list:\n",
    "            # [B, Feat_i + z, N]\n",
    "            point_local_feat_list = [self.index(im_feat, xy), z_feat]\n",
    "            \n",
    "            point_local_feat = torch.cat(point_local_feat_list, 1)\n",
    "            \n",
    "            dy_shape = point_local_feat.shape[2]\n",
    "\n",
    "            input_tensor_shape = Tensor(self.SC.input().element_type, [1, 257, dy_shape])\n",
    "            infer_request.set_input_tensor(input_tensor_shape)\n",
    "            \n",
    "            st = timeit.default_timer()\n",
    "            input_tensor = point_local_feat.cpu().numpy()\n",
    "            self.time_benchmark += timeit.default_timer() - st\n",
    "            \n",
    "            infer_request.infer([input_tensor])\n",
    "            result = infer_request.get_output_tensor()\n",
    "            \n",
    "            st = timeit.default_timer()\n",
    "            result_ten = torch.Tensor(result.data[:]).to('cpu')\n",
    "            self.time_benchmark += timeit.default_timer() - st\n",
    "            \n",
    "            pred = in_img[:,None].float() * result_ten\n",
    "            \n",
    "            \n",
    "            self.intermediate_preds_list.append(pred)\n",
    "\n",
    "        self.preds = self.intermediate_preds_list[-1]\n",
    "\n",
    "    def get_im_feat(self):\n",
    "        return self.im_feat_list[-1]\n",
    "\n",
    "    def get_preds(self):\n",
    "        return self.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dried-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mesh(net, cuda, data, save_path, use_octree=True):\n",
    "    image_tensor = data['img'].to(device=cuda)\n",
    "    calib_tensor = data['calib'].to(device=cuda)\n",
    "\n",
    "    net.filter(image_tensor)\n",
    "    b_min = data['b_min']\n",
    "    b_max = data['b_max']\n",
    "    \n",
    "    try:\n",
    "        verts, faces, _, _ = reconstruction(\n",
    "            net,\n",
    "            cuda,\n",
    "            calib_tensor,\n",
    "            RESOLUTION,\n",
    "            b_min,\n",
    "            b_max,\n",
    "            use_octree=use_octree\n",
    "        )\n",
    "            \n",
    "        verts_tensor = torch.from_numpy(verts.T).unsqueeze(0).to(device=cuda).float()\n",
    "        xyz_tensor = net.projection(verts_tensor, calib_tensor[:1])\n",
    "        uv = xyz_tensor[:, :2, :]\n",
    "        color = index(image_tensor[:1], uv).detach().cpu().numpy()[0].T\n",
    "        color = color * 0.5 + 0.5\n",
    "        save_obj_mesh_with_color(save_path, verts, faces, color)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Can not create marching cubes at this time.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-windows",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "published-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = './input_images\\\\ryota.png'\n",
    "MASK_PATH = './input_images\\\\ryota_mask.png'\n",
    "\n",
    "data = load_image(IMAGE_PATH, MASK_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-ability",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "touched-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "netG = HGPIFuNet().to(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "useful-works",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Cost:  17.6128049\n"
     ]
    }
   ],
   "source": [
    "save_path = '%s/%s/result_notebook_version_%s.obj' % (RESULTS_PATH, NAME, data['name'])\n",
    "st = timeit.default_timer()\n",
    "gen_mesh(netG, 'cpu', data, save_path=save_path, use_octree=True)\n",
    "print('Time Cost: ', timeit.default_timer() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "defined-trustee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012721599999988786"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG.time_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-audit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
